{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "import tensorflow as tf\n",
    "from fast_rcnn.config import cfg\n",
    "from fast_rcnn.test import im_detect\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "from utils.timer import Timer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys, cv2\n",
    "from networks.factory import get_network\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = ('__background__',\n",
    "           'empty_basket', 'full_basket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#im_dir = 'VOCdevkit/VOC2007/JPEGImages'\n",
    "im_dir = 'demo/shopping_for_bratwurst'\n",
    "#im_list_dir = 'VOCdevkit/VOC2007/ImageSets/Main'\n",
    "im_list_dir = 'demo/shopping_for_bratwurst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_detections(im, class_name, dets,ax, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    if len(inds) == 0:\n",
    "        return\n",
    "\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo(sess, net, image_name):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "    im_file = os.path.join(cfg.DATA_DIR, im_dir, image_name)\n",
    "    im = cv2.imread(im_file)\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(sess, net, im)\n",
    "    timer.toc()\n",
    "    print ('Detection took {:.3f}s for '\n",
    "           '{:d} object proposals').format(timer.total_time, boxes.shape[0])\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "\n",
    "    CONF_THRESH = 0.4\n",
    "    NMS_THRESH = 0.3\n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(dets, NMS_THRESH)\n",
    "        dets = dets[keep, :]\n",
    "        vis_detections(im, cls, dets, ax, thresh=CONF_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/rpn_cls_score:0\", shape=(?, ?, ?, 18), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob_reshape:0\", shape=(?, ?, ?, 18), dtype=float32)\n",
      "Tensor(\"rpn_bbox_pred/rpn_bbox_pred:0\", shape=(?, ?, ?, 36), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rois:0\", shape=(?, 5), dtype=float32)\n",
      "[<tf.Tensor 'conv5_3/conv5_3:0' shape=(?, ?, ?, 512) dtype=float32>, <tf.Tensor 'rois:0' shape=(?, 5) dtype=float32>]\n",
      "Tensor(\"fc7/fc7:0\", shape=(?, 4096), dtype=float32)\n",
      "\n",
      "\n",
      "Loaded network /root/faster_rcnn/output/BSKT_VGG16/voc_2007_trainval/VGGnet_fast_rcnn_iter_20000.ckpt\n"
     ]
    }
   ],
   "source": [
    "cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "\n",
    "gpu, inference_net = 0, 'VGGnet_test'\n",
    "weights_path = '/root/faster_rcnn/output/BSKT_VGG16/voc_2007_trainval'\n",
    "weights = os.path.join(weights_path,'VGGnet_fast_rcnn_iter_20000.ckpt')\n",
    "\n",
    "# init session\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "# load network\n",
    "net = get_network(inference_net)\n",
    "# load model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, weights)\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "print '\\n\\nLoaded network {:s}'.format(weights)\n",
    "\n",
    "# Warmup on a dummy image\n",
    "im = 128 * np.ones((300, 300, 3), dtype=np.uint8)\n",
    "for i in xrange(2):\n",
    "    _, _= im_detect(sess, net, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running inference on IMG_0265.jpg.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1b8f53ca4660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Running inference on {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b75aed8d0371>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(sess, net, image_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     print ('Detection took {:.3f}s for '\n",
      "\u001b[0;32m/root/faster_rcnn/lib/fast_rcnn/test.pyc\u001b[0m in \u001b[0;36mim_detect\u001b[0;34m(sess, net, im, boxes)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mblobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_scales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# When mapping from image ROIs to feature map ROIs, there's some aliasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/faster_rcnn/lib/fast_rcnn/test.pyc\u001b[0m in \u001b[0;36m_get_blobs\u001b[0;34m(im, rois)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHAS_RPN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mblobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rois'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_scale_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_image_blob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mblobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rois'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/faster_rcnn/lib/fast_rcnn/test.pyc\u001b[0m in \u001b[0;36m_get_image_blob\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mpyramid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mim_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mim_orig\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIXEL_MEANS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "im_names = [line.rstrip('\\n') for line in open(os.path.join(cfg.DATA_DIR, im_list_dir, 'test.txt'))]\n",
    "for im_name in im_names:\n",
    "    im_name += '.jpg'\n",
    "    print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n",
    "    print 'Running inference on {}'.format(im_name)\n",
    "    demo(sess, net, im_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
